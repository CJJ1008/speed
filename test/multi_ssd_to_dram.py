#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import time
import mmap
import zlib
import argparse
import subprocess
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime

ALIGN = 4096               # O_DIRECT å¸¸è§å¯¹é½è¦æ±‚
CHECK_SAMPLE = 64 * 1024   # æ¯æ¬¡åªæŠ½æ · 64KB åšæ ¡éªŒï¼Œé¿å… CPU æˆç“¶é¢ˆ


def human_size(n: int) -> str:
    units = ["B", "KB", "MB", "GB", "TB"]
    x = float(n)
    i = 0
    while x >= 1024 and i < len(units) - 1:
        x /= 1024.0
        i += 1
    return f"{x:.2f} {units[i]}"


def round_down(n: int, align: int = ALIGN) -> int:
    return (n // align) * align


def get_mount_device(path: str) -> str:
    """ç”¨ df -P è·å–ç›®å½•æ‰€åœ¨å—è®¾å¤‡ï¼ˆç¡®è®¤æ˜¯ä¸æ˜¯ä¸åŒ NVMeï¼‰"""
    try:
        out = subprocess.check_output(["df", "-P", path], text=True).strip().splitlines()
        if len(out) >= 2:
            return out[-1].split()[0]
    except Exception:
        pass
    return "UNKNOWN"


def try_drop_caches() -> bool:
    """å°½é‡æ¸… page cacheï¼ˆéœ€è¦ root ä¸”å®¹å™¨å…è®¸ï¼‰"""
    try:
        subprocess.run(["sync"], check=False)
        with open("/proc/sys/vm/drop_caches", "w") as f:
            f.write("3\n")
        return True
    except Exception:
        return False


def open_for_direct(path: str, flags: int, direct: bool):
    """è¿”å› (fd, used_direct)"""
    if direct and hasattr(os, "O_DIRECT"):
        try:
            fd = os.open(path, flags | os.O_DIRECT, 0o644)
            return fd, True
        except OSError:
            pass
    fd = os.open(path, flags, 0o644)
    return fd, False


def safe_unlink(path: str):
    try:
        os.remove(path)
    except Exception:
        pass


def write_full_file(path: str, size_bytes: int, chunk_size: int, direct: bool, require_direct: bool) -> bool:
    """
    ç”Ÿæˆâ€œçœŸè½ç›˜â€çš„æµ‹è¯•æ–‡ä»¶ï¼šå†™æ»¡æ•°æ® + fsync
    è¿”å› used_direct
    """
    safe_unlink(path)

    fd, used_direct = open_for_direct(path, os.O_WRONLY | os.O_CREAT | os.O_TRUNC, direct=direct)
    if require_direct and not used_direct:
        os.close(fd)
        raise RuntimeError(f"[prepare] O_DIRECT æ‰“ä¸å¼€: {path}")

    # mmap(-1, chunk_size) å¾—åˆ°é¡µå¯¹é½ buffer
    buf = mmap.mmap(-1, chunk_size, access=mmap.ACCESS_WRITE)
    mv = memoryview(buf)

    # å¡«ä¸€æ¬¡éšæœºå—ï¼Œé‡å¤å†™ï¼ˆå†…å®¹ä¸é‡è¦ï¼Œå…³é”®æ˜¯çœŸå†™ç›˜ï¼‰
    mv[:] = os.urandom(chunk_size)

    written = 0
    try:
        while written < size_bytes:
            to_write = min(chunk_size, size_bytes - written)
            if used_direct and (to_write % ALIGN != 0):
                to_write = round_down(to_write, ALIGN)
                if to_write == 0:
                    break

            view = mv[:to_write]
            os.writev(fd, [view])
            view.release()
            del view

            written += to_write

        os.fsync(fd)
    finally:
        mv.release()
        buf.close()
        os.close(fd)

    return used_direct


def read_full_file(path: str, size_bytes: int, chunk_size: int, direct: bool, require_direct: bool) -> dict:
    """
    é¡ºåºè¯»å…¨æ–‡ä»¶ï¼šè¯»åˆ° mmap bufferï¼Œä¸ä¿å­˜ï¼›æŠ½æ ·åš adler32 æ ¡éªŒ
    è¿”å› {time, checksum, used_direct, bytes_read}
    """
    fd, used_direct = open_for_direct(path, os.O_RDONLY, direct=direct)
    if require_direct and not used_direct:
        os.close(fd)
        raise RuntimeError(f"[read] O_DIRECT æ‰“ä¸å¼€: {path}")

    buf = mmap.mmap(-1, chunk_size, access=mmap.ACCESS_WRITE)
    mv = memoryview(buf)

    checksum = 1
    remaining = size_bytes
    bytes_read = 0

    start = time.perf_counter()
    try:
        while remaining > 0:
            to_read = min(chunk_size, remaining)
            if used_direct and (to_read % ALIGN != 0):
                to_read = round_down(to_read, ALIGN)
                if to_read == 0:
                    break

            view = mv[:to_read]
            n = os.readv(fd, [view])
            view.release()
            del view

            if n <= 0:
                break

            bytes_read += n

            # æŠ½æ ·å‰ 64KBï¼šç”¨ bytes(...) å¤åˆ¶å‡ºæ¥ï¼Œç¡®ä¿ä¸ç•™ä»»ä½•æŒ‡å‘ mmap çš„ view
            k = min(n, CHECK_SAMPLE)
            sample_bytes = bytes(mv[:k])
            checksum = zlib.adler32(sample_bytes, checksum)

            remaining -= n
    finally:
        end = time.perf_counter()
        mv.release()
        buf.close()
        os.close(fd)

    return {"time": end - start, "checksum": checksum, "used_direct": used_direct, "bytes_read": bytes_read}


def build_file_paths(dirs: list[str], prefix: str) -> list[str]:
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    return [os.path.join(d, f"{prefix}_part{i}_{ts}.bin") for i, d in enumerate(dirs)]


def main():
    ap = argparse.ArgumentParser(description="å¤šç›˜å¹¶å‘ SSD->DRAM è¯»å¸¦å®½æµ‹è¯•ï¼ˆåˆ†ç‰‡/å¤šNVMeå¹¶å‘ï¼Œå¸¦å®½å åŠ ï¼‰")
    ap.add_argument("--dirs", nargs="+", required=True,
                    help="æ¯å— NVMe å¯¹åº”ä¸€ä¸ªå·²æŒ‚è½½ç›®å½•ï¼ˆä¾‹å¦‚ /mnt/nvme0 /mnt/nvme1 ...ï¼‰")
    ap.add_argument("--min-total-gb", type=float, default=1.0, help="æœ€å°æ€»æ•°æ®é‡ï¼ˆGBï¼Œè·¨æ‰€æœ‰ç›˜æ±‚å’Œï¼‰")
    ap.add_argument("--max-total-gb", type=float, default=8.0, help="æœ€å¤§æ€»æ•°æ®é‡ï¼ˆGBï¼Œè·¨æ‰€æœ‰ç›˜æ±‚å’Œï¼‰")
    ap.add_argument("--rounds", type=int, default=3, help="æ¯ä¸ªå¤§å°é‡å¤è¯»æ¬¡æ•°å–å¹³å‡")
    ap.add_argument("--chunk-mb", type=int, default=16, help="è¯»å†™å—å¤§å°ï¼ˆMBï¼Œå»ºè®® 8/16/32ï¼‰")
    ap.add_argument("--no-direct", action="store_true", help="ç¦ç”¨ O_DIRECTï¼ˆä¸æ¨èï¼‰")
    ap.add_argument("--require-direct", action="store_true", help="å¿…é¡»ä½¿ç”¨ O_DIRECTï¼Œå¦åˆ™æŠ¥é”™é€€å‡º")
    ap.add_argument("--drop-caches", action="store_true", help="æ¯è½®è¯»å‰å°è¯• drop_cachesï¼ˆä¸€èˆ¬ O_DIRECT ä¸éœ€è¦ï¼‰")
    ap.add_argument("--keep-files", action="store_true", help="ä¿ç•™æµ‹è¯•æ–‡ä»¶ï¼ˆé»˜è®¤åˆ é™¤ï¼‰")
    args = ap.parse_args()

    dirs = [os.path.abspath(d) for d in args.dirs]
    for d in dirs:
        os.makedirs(d, exist_ok=True)

    n = len(dirs)
    direct = not args.no_direct
    chunk_size = args.chunk_mb * 1024 * 1024

    if chunk_size % ALIGN != 0:
        raise ValueError("chunk-mb å¿…é¡»ä½¿ chunk_size ä¸º 4096 çš„å€æ•°ï¼ˆä¾‹å¦‚ 8/16/32MBï¼‰")

    print("===== å¤šç›˜ SSD->DRAM è¯»å¸¦å®½æµ‹è¯• =====")
    print(f"ç›®æ ‡ç›˜æ•°: {n}")
    for d in dirs:
        print(f"  {d}  ->  {get_mount_device(d)}")
    print(f"O_DIRECT: {'ON' if direct else 'OFF'} | require_direct: {args.require_direct}")
    print(f"chunk: {args.chunk_mb} MB | rounds: {args.rounds}")
    print(f"total size: {args.min_total_gb} GB -> {args.max_total_gb} GB (doubling)")
    print(f"drop_caches_each_round: {'ON' if args.drop_caches else 'OFF'}")
    print("====================================\n")

    log_name = f"multi_ssd_to_dram_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    with open(log_name, "w", encoding="utf-8") as lf:
        lf.write(f"multi SSD->DRAM read test  {datetime.now().isoformat()}\n")
        for d in dirs:
            lf.write(f"dir: {d} -> {get_mount_device(d)}\n")
        lf.write("=" * 140 + "\n")
        lf.write("total_size\tper_disk_size\tavg_wall_s\tagg_GBps\tagg_MBps\tper_disk_MBps_list\tdirect_used\tchecksum_sum\tbytes_read\n")

    total_min = int(args.min_total_gb * (1024**3))
    total_max = int(args.max_total_gb * (1024**3))
    total = total_min

    files = []
    try:
        while total <= total_max:
            per = round_down(total // n, ALIGN)
            real_total = per * n
            if per <= 0:
                raise RuntimeError("æ€»å¤§å°å¤ªå°ï¼Œåˆ†ç‰‡å per_disk_size=0")

            print(f"== å‡†å¤‡æ•°æ®ï¼štotal={human_size(real_total)}  per_disk={human_size(per)} ==")
            files = build_file_paths(dirs, prefix="read_test")

            # å¹¶å‘å†™æ»¡æ–‡ä»¶ï¼ˆå‡†å¤‡é˜¶æ®µï¼‰
            with ThreadPoolExecutor(max_workers=n) as ex:
                futs = [ex.submit(write_full_file, files[i], per, chunk_size, direct, args.require_direct) for i in range(n)]
                used_direct_list = [f.result() for f in as_completed(futs)]

            used_direct_prepare = all(used_direct_list) if used_direct_list else False
            print(f"å‡†å¤‡å®Œæˆï¼ˆå†™æ»¡å¹¶ fsyncï¼‰ã€‚O_DIRECT_used_in_prepare={used_direct_prepare}\n")

            # å¹¶å‘è¯»æµ‹é€Ÿï¼šæŒ‰è½®ç»Ÿè®¡ wall timeï¼ˆå¸¦å®½å åŠ ï¼‰
            wall_sum = 0.0
            last_per_disk_mb = None
            direct_used = True
            checksum_sum = 0
            bytes_read_sum = 0

            for r in range(args.rounds):
                if args.drop_caches:
                    ok = try_drop_caches()
                    print(f"[round {r+1}] drop_caches: {'OK' if ok else 'FAIL/IGNORED'}")

                start_round = time.perf_counter()
                per_disk_stats = [None] * n

                with ThreadPoolExecutor(max_workers=n) as ex:
                    fut_map = {}
                    for i in range(n):
                        fut = ex.submit(read_full_file, files[i], per, chunk_size, direct, args.require_direct)
                        fut_map[fut] = i

                    for fut in as_completed(fut_map):
                        i = fut_map[fut]
                        per_disk_stats[i] = fut.result()

                end_round = time.perf_counter()
                wall = end_round - start_round
                wall_sum += wall

                per_disk_mb = []
                checks = 0
                bytes_read = 0
                for st in per_disk_stats:
                    per_disk_mb.append((per / 1024 / 1024) / st["time"])
                    checks += int(st["checksum"])
                    bytes_read += int(st["bytes_read"])
                    direct_used = direct_used and bool(st["used_direct"])

                last_per_disk_mb = per_disk_mb
                checksum_sum = checks
                bytes_read_sum = bytes_read

                agg_mb = (real_total / 1024 / 1024) / wall
                agg_gb = (real_total / 1024 / 1024 / 1024) / wall

                print(f"[round {r+1}] wall={wall:.4f}s  AGG={agg_mb:.2f} MB/s ({agg_gb:.4f} GB/s) "
                      f"| per-disk MB/s: " + ", ".join(f"{x:.1f}" for x in per_disk_mb))

            avg_wall = wall_sum / args.rounds
            agg_mb_avg = (real_total / 1024 / 1024) / avg_wall
            agg_gb_avg = (real_total / 1024 / 1024 / 1024) / avg_wall

            print(f"\nâœ… RESULT total={human_size(real_total)} per_disk={human_size(per)} "
                  f"| avg_wall={avg_wall:.4f}s | AGG={agg_mb_avg:.2f} MB/s ({agg_gb_avg:.4f} GB/s) "
                  f"| direct_used={direct_used}\n")

            with open(log_name, "a", encoding="utf-8") as lf:
                lf.write(
                    f"{human_size(real_total)}\t{human_size(per)}\t{avg_wall:.6f}\t{agg_gb_avg:.6f}\t{agg_mb_avg:.2f}\t"
                    f"{','.join(f'{x:.1f}' for x in (last_per_disk_mb or []))}\t{direct_used}\t{checksum_sum}\t{bytes_read_sum}\n"
                )

            if not args.keep_files:
                for p in files:
                    safe_unlink(p)
                print("ğŸ—‘ï¸ å·²åˆ é™¤æœ¬è½®æµ‹è¯•æ–‡ä»¶ï¼ˆé‡Šæ”¾ç©ºé—´ï¼‰\n")

            total *= 2

    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿå¼‚å¸¸: {repr(e)}")
        print("æç¤ºï¼šå¦‚æœè„šæœ¬å¼‚å¸¸é€€å‡ºï¼Œå¯èƒ½ç•™ä¸‹ read_test_part*.binï¼Œå¯ä»¥æ‰‹åŠ¨ rm æ‰ã€‚")
        raise

    finally:
        if (not args.keep_files) and files:
            for p in files:
                safe_unlink(p)
        print(f"æ—¥å¿—æ–‡ä»¶: {log_name}")


if __name__ == "__main__":
    main()

